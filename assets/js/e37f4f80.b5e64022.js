"use strict";(self.webpackChunkmynameis=self.webpackChunkmynameis||[]).push([[343],{1232:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>l});var o=t(5893),s=t(1151);const i={slug:"big-json",title:"250mb json in a 40mb service limit",authors:["denis"],tags:["software"]},a=void 0,r={permalink:"/mynameis/blog/big-json",source:"@site/blog/02-250mbjson-in-50mb-limit/index.mdx",title:"250mb json in a 40mb service limit",description:"This article has been created to remind us of one simple thing: HTTP is a stream.",date:"2024-05-26T15:48:12.000Z",formattedDate:"May 26, 2024",tags:[{label:"software",permalink:"/mynameis/blog/tags/software"}],readingTime:6.8,hasTruncateMarker:!0,authors:[{name:"Denis",title:"Software Experience Dude",key:"denis"}],frontMatter:{slug:"big-json",title:"250mb json in a 40mb service limit",authors:["denis"],tags:["software"]},unlisted:!1,nextItem:{title:"Why this page exists",permalink:"/mynameis/blog/why-a-blog"}},c={authorsImageUrls:[void 0]},l=[{value:"The challenge: cut down the memory consumption as much as we can.",id:"the-challenge-cut-down-the-memory-consumption-as-much-as-we-can",level:3},{value:"3 Ways to do it",id:"3-ways-to-do-it",level:3},{value:"First, Brute Force solution.",id:"first-brute-force-solution",level:3},{value:"Second, decode object by object.",id:"second-decode-object-by-object",level:3},{value:"Third, the simplest: data compression.",id:"third-the-simplest-data-compression",level:3},{value:"Conclusion",id:"conclusion",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.p,{children:"This article has been created to remind us of one simple thing: HTTP is a stream."}),"\n",(0,o.jsx)(n.p,{children:"As a practical outcome we can learn how to reduce memory requirements for our services in a typical task: cache warming."}),"\n",(0,o.jsx)(n.p,{children:"Let's look at the challenge first."}),"\n",(0,o.jsx)(n.p,{children:"We have a service that must download the data and keep it in memory.\nThe issue is the JSON document we have to download is 10 times larger than the encoded data.\nTherefore we have to increase the memory limit 2-3 times to download it once.\nLater on, the service doesn't consume as much memory, so it's a start up cost."}),"\n",(0,o.jsx)(n.h3,{id:"the-challenge-cut-down-the-memory-consumption-as-much-as-we-can",children:"The challenge: cut down the memory consumption as much as we can."}),"\n",(0,o.jsx)(n.p,{children:"Let's get back to the basic of network communication."}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsx)(n.p,{children:"We skip TLS termination for the sake of simplicity."})}),"\n",(0,o.jsxs)(n.p,{children:["There is a great book that explains it very well: ",(0,o.jsx)(n.a,{href:"https://hpbn.co/building-blocks-of-tcp/#slow-start",children:"https://hpbn.co/building-blocks-of-tcp/#slow-start"})]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"img",src:t(8006).Z+"",width:"343",height:"171"})}),"\n",(0,o.jsx)(n.p,{children:"Just a litle picture to remind us how a connection starts: we do a handshake with the service."}),"\n",(0,o.jsx)(n.p,{children:"Then we can start exchanging data.\nTypical API responses are at most ~50kb."}),"\n",(0,o.jsx)(n.p,{children:"But what if you want to warm a cache? How much can it be?\nIt can be a lot, around tens of megabytes.\nIn my example, we take 250mb."}),"\n",(0,o.jsx)(n.p,{children:"How does the server send such data?"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"img",src:t(6678).Z+"",width:"283",height:"142"})}),"\n",(0,o.jsx)(n.p,{children:"Slowly, packet by packet."}),"\n",(0,o.jsx)(n.p,{children:"The server tries to understand your throughput. The protocol itself rarely provides an accurate value of a packet size, so by relying on the imperical latency, it tunes the packet size little by little.\nIt needs to send a lot of packets to transfer a really big response."}),"\n",(0,o.jsx)(n.h3,{id:"3-ways-to-do-it",children:"3 Ways to do it"}),"\n",(0,o.jsx)(n.p,{children:"Below we will consider 3 approaches to solve this task.\nThere is no such thing as the only right solution; all of them are fine as long as you understand the costs and risks well enough, and we are gonna cover them."}),"\n",(0,o.jsx)(n.h3,{id:"first-brute-force-solution",children:"First, Brute Force solution."}),"\n",(0,o.jsx)(n.admonition,{type:"warning",children:(0,o.jsx)(n.p,{children:"If you want to reproduce an example make sure to untar server/json.tar.gz; it must contain the f.json file since GitHub has a limit of up to 100mb for a file."})}),"\n",(0,o.jsx)(n.p,{children:"You can imagine how the simplest Go HTTP client can implement it or just look at the code."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://github.com/dennypenta/http-response-lab/blob/543510947c0b19dbc0097adf403ae5cd6954c1cc/client/main.go",children:"Link"})}),"\n",(0,o.jsx)(n.p,{children:"The implementation is straight forward: it sends a request, gets a response, reads, marhsals it into a defined structure, holds it in the memory and ready to serve it further."}),"\n",(0,o.jsx)(n.p,{children:"And here is the pprof output:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"Showing nodes accounting for 229.48MB, 100% of 229.48MB total\n      flat  flat%   sum%        cum   cum%\n  229.48MB   100%   100%   229.48MB   100%  io.ReadAll\n         0     0%   100%   229.48MB   100%  main.main\n         0     0%   100%   229.48MB   100%  runtime.main\n"})}),"\n",(0,o.jsx)(n.p,{children:"Yes, it's not real win, with huge memory consumption, but it works ok."}),"\n",(0,o.jsx)(n.p,{children:"We see all the memory consumed on reading the HTTP stream."}),"\n",(0,o.jsxs)(n.p,{children:['Or you might say, "What a noob, you must use ',(0,o.jsx)(n.code,{children:"json.Decoder"}),'" so as to let the decoder work with the HTTP pipe closer.']}),"\n",(0,o.jsxs)(n.p,{children:["And it's pretty much the same, in my example, even worse.\n",(0,o.jsx)(n.a,{href:"https://github.com/dennypenta/http-response-lab/blob/b6ee7fcfd69fdffad844eb6a3d324d2fe3040985/client/main.go",children:"Link"})," to code with Decoder"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"Showing nodes accounting for 384MB, 100% of 384MB total\n      flat  flat%   sum%        cum   cum%\n     384MB   100%   100%      384MB   100%  encoding/json.(*Decoder).refill\n         0     0%   100%      384MB   100%  encoding/json.(*Decoder).Decode\n         0     0%   100%      384MB   100%  encoding/json.(*Decoder).readValue\n         0     0%   100%      384MB   100%  main.main\n         0     0%   100%      384MB   100%  runtime.main\n"})}),"\n",(0,o.jsxs)(n.p,{children:["To recall why let's dig a little into the json/encoding library ",(0,o.jsx)(n.a,{href:"https://cs.opensource.google/go/go/+/refs/tags/go1.22.3:src/encoding/json/stream.go;l=49",children:"implementation"}),"."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-go",children:'func (dec *Decoder) Decode(v any) error {\n\tif dec.err != nil {\n\t\treturn dec.err\n\t}\n\n\tif err := dec.tokenPrepareForDecode(); err != nil {\n\t\treturn err\n\t}\n\n\tif !dec.tokenValueAllowed() {\n\t\treturn &SyntaxError{msg: "not at beginning of value", Offset: dec.InputOffset()}\n\t}\n\n\t// Read whole value into buffer.\n\tn, err := dec.readValue()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdec.d.init(dec.buf[dec.scanp : dec.scanp+n])\n\tdec.scanp += n\n\n\t// Don\'t save err from unmarshal into dec.err:\n\t// the connection is still usable since we read a complete JSON\n\t// object from it before the error happened.\n\terr = dec.d.unmarshal(v)\n\n\t// fixup token streaming state\n\tdec.tokenValueEnd()\n\n\treturn err\n}\n'})}),"\n",(0,o.jsxs)(n.p,{children:["It does exactly the same, it calls ",(0,o.jsx)(n.code,{children:"dec.readValue()"})," first to read all the response and then ",(0,o.jsx)(n.code,{children:"dec.d.unmarshal"})," to parse it."]}),"\n",(0,o.jsxs)(n.p,{children:["And it's ok; the reason is very simple: ",(0,o.jsx)(n.strong,{children:"encoding/json doesn't know the nature of your data."})]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["Libraries like ",(0,o.jsx)(n.a,{href:"https://github.com/json-iterator/go",children:"json-iter"})," or ",(0,o.jsx)(n.a,{href:"https://github.com/mailru/easyjson",children:"easyjson"})," offer zero improvements in memory consumption."]})}),"\n",(0,o.jsx)(n.h3,{id:"second-decode-object-by-object",children:"Second, decode object by object."}),"\n",(0,o.jsxs)(n.p,{children:["Go json library provides a method of the Decoder called ",(0,o.jsx)(n.a,{href:"https://pkg.go.dev/encoding/json#Decoder.Token",children:(0,o.jsx)(n.code,{children:"Token"})})]}),"\n",(0,o.jsx)(n.p,{children:"This approach, parsing manually token by token, can give us an option to manually parse the json.\nA token might be every symbol, such as as open bracket, quote, key, value, etc.\nBut I found this approach quite complex. Having a deeply nested JSON object makes it very confusing to understand the relation for a given token. An solution could be to hold every key and designated level, but the decision gets worse with duplicated keys on a couple of levels."}),"\n",(0,o.jsx)(n.p,{children:"That's why I prefer another approach."}),"\n",(0,o.jsxs)(n.p,{children:['There is a well-known problem on LeetCode called "',(0,o.jsx)(n.a,{href:"https://leetcode.com/problems/valid-parentheses/description/",children:"Valid Parentheses"}),'"']}),"\n",(0,o.jsx)(n.p,{children:"We can simply read the beginning of a given object and the end, understanding when the last bracket of the object comes."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://github.com/dennypenta/http-response-lab/blob/b5890cbb74282416b5adacc92de95f18f7ee766f/client/main.go#L110",children:"Link"})}),"\n",(0,o.jsx)(n.p,{children:"pprof gives the following output"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"(pprof) top 5\nShowing nodes accounting for 68.56MB, 100% of 68.56MB total\nShowing top 5 nodes out of 10\n      flat  flat%   sum%        cum   cum%\n   27.55MB 40.18% 40.18%    68.56MB   100%  main.decode\n      20MB 29.17% 69.35%       20MB 29.17%  encoding/json.(*decodeState).literalStore\n      20MB 29.17% 98.52%       20MB 29.17%  bufio.NewReaderSize (inline)\n    1.01MB  1.48%   100%     1.01MB  1.48%  bufio.(*Scanner).Text (inline)\n         0     0%   100%       20MB 29.17%  encoding/json.(*decodeState).object\n"})}),"\n",(0,o.jsx)(n.p,{children:"Usually, the output varies between 65-80mb."}),"\n",(0,o.jsxs)(n.p,{children:["Such adventages is achieved due to marshalling the json ",(0,o.jsx)(n.strong,{children:"and"})," reading the HTTP response at the same time."]}),"\n",(0,o.jsx)(n.p,{children:"Let's get back to the introduction. Such a huge response gives us a stream of HTTP chunks we read step by step until the FIN message comes.\nWe can't make the HTTP server split every object in the response for us (probably we can, but it brings even more complexity).\nInstead, every given chunk window we can ask, \"Does it contain a valid json object?\""}),"\n",(0,o.jsxs)(n.p,{children:["As soon as a valid object has come, we can marshal it and continue reading the response further ",(0,o.jsx)(n.strong,{children:"until the next valid JSON object comes"}),"."]}),"\n",(0,o.jsx)(n.h3,{id:"third-the-simplest-data-compression",children:"Third, the simplest: data compression."}),"\n",(0,o.jsx)(n.p,{children:"It was new to me to discover that the most efficient solution will nott be related to the response handling."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"We simply must transfer as little data as we can."})}),"\n",(0,o.jsx)(n.p,{children:"JSON is not the only way to represent the data.\nIt's easy and human-readable, but sometimes we have to trade it."}),"\n",(0,o.jsx)(n.p,{children:"There are plenty of formats we can apply:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Avro"}),"\n",(0,o.jsx)(n.li,{children:"Tthrift"}),"\n",(0,o.jsx)(n.li,{children:"MessagePack"}),"\n",(0,o.jsx)(n.li,{children:"Gob (Go only)"}),"\n",(0,o.jsx)(n.li,{children:"Protobuf"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"And most likely more I don't even know."}),"\n",(0,o.jsx)(n.p,{children:"I tried replacing decoding to MessagePack and gave very litle result (zero _(\u30c4)_/)."}),"\n",(0,o.jsx)(n.p,{children:"The best outcome showed Protobuf."}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsx)(n.p,{children:"We still use HTTP/1.1; we don't use gRPC transport."})}),"\n",(0,o.jsx)(n.p,{children:"The output from pprof is even better with less effort to implement.\nIt may vary up to 50mb sometimes."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"(pprof) top5\nShowing nodes accounting for 30.79MB, 100% of 30.79MB total\n      flat  flat%   sum%        cum   cum%\n   30.79MB   100%   100%    30.79MB   100%  io.ReadAll\n         0     0%   100%    30.79MB   100%  main.decode\n         0     0%   100%    30.79MB   100%  main.main\n         0     0%   100%    30.79MB   100%  runtime.main\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Here is the solution: ",(0,o.jsx)(n.a,{href:"https://github.com/dennypenta/http-response-lab/blob/main/client/main.go#L14",children:"Link"})]}),"\n",(0,o.jsx)(n.p,{children:"What we can say about Gob?"}),"\n",(0,o.jsx)(n.p,{children:"It offers very specific decoding and is a Go-only implementation, but it doesn't provide any benefit, here is the pprof output"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"(pprof) top5\nShowing nodes accounting for 70.81MB, 100% of 70.81MB total\nShowing top 5 nodes out of 20\n      flat  flat%   sum%        cum   cum%\n   30.53MB 43.12% 43.12%    30.53MB 43.12%  internal/saferio.ReadData\n   28.28MB 39.94% 83.05%    28.28MB 39.94%  reflect.growslice\n      12MB 16.95%   100%       12MB 16.95%  encoding/gob.decString\n         0     0%   100%    70.81MB   100%  encoding/gob.(*Decoder).Decode\n         0     0%   100%    70.81MB   100%  encoding/gob.(*Decoder).DecodeValue\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Perhaps for someone, having schemaless implementation is valuable, so here is the solution ",(0,o.jsx)(n.a,{href:"https://github.com/dennypenta/http-response-lab/blob/main/client/main.go#L40",children:"link"})]}),"\n",(0,o.jsx)(n.h3,{id:"conclusion",children:"Conclusion"}),"\n",(0,o.jsx)(n.p,{children:"I found 2 interesting ideas to me during the investigation."}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"The best, or one of them, solution might be the most obvious, so obvious to one is not to everyone."}),"\n",(0,o.jsx)(n.li,{children:"It's not hard to implement and dig into fundamentals; some may win from engineering a new bicycle."}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},6678:(e,n,t)=>{t.d(n,{Z:()=>o});const o=t.p+"assets/images/congestion-d6e58562593cc5752c5bc8b39ab87735.svg"},8006:(e,n,t)=>{t.d(n,{Z:()=>o});const o=t.p+"assets/images/syn-b9d07c0830813f49866fd02e5f6dcacb.svg"},1151:(e,n,t)=>{t.d(n,{Z:()=>r,a:()=>a});var o=t(7294);const s={},i=o.createContext(s);function a(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);